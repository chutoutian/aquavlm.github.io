<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="AquaScope: Reliable Underwater Image Transmission on Mobile Devices.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>AquaVLM: Improving Underwater Situation Awareness with Mobile Vision Language Models</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/diving-mask.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://chutoutian.github.io/aquascope.github.io/">
            AquaScope
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">AquaVLM: Improving Underwater Situation Awareness with Mobile Vision Language Models</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.beitongtian.com/">Beitong Tian</a><sup>*</sup>,</span>
            <span class="author-block">
              <a href="https://chutoutian.github.io/">Lingzhi Zhao</a><sup>*</sup>,</span>
            <span class="author-block">
              <a href="https://bochen.info/">Bo Chen</a><sup></sup>,
            </span>
            <span class="author-block">
              <a href="">Haozhen Zheng</a><sup></sup>,
            </span>
            <span class="author-block">
              <a href="https://jingcheng.me/">Jingcheng Yang</a><sup></sup>,
            </span>
            <span class="author-block">
              <a href="https://mingyuan1997.github.io/">Mingyuan Wu</a><sup></sup>,
            </span>
            <span class="author-block">
              <a href="https://deepakv.web.illinois.edu/">Deepak Vasisht</a><sup></sup>,
            </span>
              <span class="author-block">
              <a href="https://monet.cs.illinois.edu/people/klara/">Klara Nahrstedt</a><sup></sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup></sup>University of Illinois Urbana-Champaign,</span>
          <span class="author-block"><sup>*</sup>Equal Contribution</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2510.21722"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2510.21722"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/underwater-uiuc/AquaVLM"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://drive.google.com/drive/u/3/folders/16Vg5WqB1uViH2m_2Lx3VoU5_eZO_LtZ8"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!--
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2>
    </div>
  </div>
</section>
-->




<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Underwater activities like scuba diving enable millions annually to explore marine environments for recreation and scientific research. Maintaining situational awareness and effective communication are essential for diver safety. Traditional underwater communication systems are often bulky and expensive, limiting their accessibility to divers of all levels. While recent systems leverage lightweight smartphones and support text messaging, the messages are predefined and thus restrict context-specific communication.
          </p>
          <p>
            In this project, we present AquaVLM, a tap-and-send underwater communication system that automatically generates context-aware messages and transmits them using ubiquitous smartphones. Our system features a mobile vision-language model (VLM) fine-tuned on an auto-generated underwater conversation dataset and employs a hierarchical message generation pipeline. We co-design the VLM and transmission, incorporating error-resilient fine-tuning to improve the system's robustness to transmission errors. We develop a VR simulator to enable users to experience AquaVLM in a realistic underwater environment and create a fully functional prototype on the iOS platform for real-world experiments. Both subjective and objective evaluations validate the effectiveness of AquaVLM and highlight its potential for personal underwater communication as well as broader mobile VLM applications.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->


  </div>

</section>


<section class="section">
  <div class="container is-max-desktop">

    <h2 class="title is-3">Illustration</h2>
        <div class="content has-text-justified">
          <p>
      Alice mounts her mobile phone on her arm, captures an image of the shark, and selects the "SOS" purpose on the user interface. 
      The mobile phone forms a prompt using <strong> multimodal data: the image, recent sensor data (e.g., compass orientation and depth), and her SOS purpose</strong>. The mobile VLM generates two message candidates.  Alice selects a message to send.
      </p>
          <p> 
      The message is modulated into an acoustic signal by the signal processing module and transmitted via the phone’s speaker. At the receiving end, the acoustic signal is demodulated and converted back into a human-readable message. In case of errors (e.g., altered characters), the mobile VLM attempts to <strong> recover the original message </strong>. The received message is displayed on Bob’s phone screen, and two reply candidates are generated based on his selected purpose.
          </p>
        </div>
        <div class="content has-text-centered">
          <img class="system-overview-image" src="./static/images/workflow.png">
        </div>
        <h2 class="title is-3">Model Instruction Tuning Pipeline</h2>
        <div class="content has-text-justified">
          <p>
            The instruction tuning pipeline consists of four stages: (a) We self-collect images from five scuba diving videos and use nine types of critical sensor data typically available on
mobile devices or diving watches. (b) We generate underwater conversation using commercial VLMs, ChatGPT-4o, leveraging self-collected multimodal data and carefully designed prompts. (c) We identify three tasks for intruction tuning: <strong>sender message generation, reply generation, and message recovery </strong>. (d) We fine-tune the MobileVLM2 using LoRA.
          </p>
        </div>
        <div class="content has-text-centered">
          <img class="tuning-pipeline-image" src="./static/images/tuning.png">
        </div>


                <!-- Interpolating. -->
        <h2 class="title is-3">VR-based Simulation</h2>
        <div class="content has-text-justified">
          <p>
            To evaluate the effectiveness of AquaVLM, we design and build a virtual reality (VR)-based simulation platform that enables users to wear a headset to explore an underwater world, experience various events, and communicate with virtual divers using AquaVLM at any point during the simulation.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel is-variable is-2">
          <div class="column is-one-third has-text-centered">
            <img src="./static/images/vr1.webp"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>Testbed</p>
          </div>
            <div class="column is-one-third has-text-centered">
            <img src="./static/images/vr2.webp"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>Different events</p>
          </div>
          <div class="column is-one-third has-text-centered">
            <img src="./static/images/vr3.webp"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">Snapshot</p>
          </div>
        </div>
        <br/>
        <!--/ Interpolating. -->
        <!-- Interpolating. -->
        <h2 class="title is-3">Prototype</h2>
        <div class="content has-text-justified">
          <p>
            We developed a prototype using an iPhone 12 Pro and Apple Watch Ultra and conducted tests in a lake with a maximum range of 20m and an averagedepth of 3m.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel is-variable is-2">
          <div class="column is-half has-text-centered">
            <img src="./static/images/ios_watch_prototype.png"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>iOS prototype</p>
          </div>
            <div class="column is-half has-text-centered">
            <img src="./static/images/environment.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>Test environment</p>
          </div>
        </div>
        <br/>
        <!--/ Interpolating. -->
  </div>
</section>







<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{tian2025aquavlmimprovingunderwatersituation,
      title={AquaVLM: Improving Underwater Situation Awareness with Mobile Vision Language Models}, 
      author={Beitong Tian and Lingzhi Zhao and Bo Chen and Haozhen Zheng and Jingcheng Yang and Mingyuan Wu and Deepak Vasisht and Klara Nahrstedt},
      year={2025},
      eprint={2510.21722},
      archivePrefix={arXiv},
      primaryClass={cs.HC},
      url={https://arxiv.org/abs/2510.21722}, 
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            
            This page was built using the <a
              href="https://github.com/eliahuhorwitz/Academic-project-page-template">Academic Project Page Template</a>
             which was adopted from the <a
              href="https://nerfies.github.io/">Nerfies</a> project page. You are free to borrow the source code of this website, we just ask that you link back to this page in the footer.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
